clip_model_root: "/net/nfs2.mosaic/yann/model/clip" 
clip_model_name: "ViT-B32"
data_root: "/home/yanpengz/data/clotho"
prompt: "the sound of"
data_name: 'clotho_captions_development' 
eval_name: 'clotho_captions_validation'
test_name: 'clotho_captions_evaluation' 
eval_samples: 5000
test_samples: 5000
peep_rate: 16 
save_rate: 32 
batch_size: 50 
epochs: 32
save_epoch: False
np_rnd: False
imagine: False
retrieval: False
mixup_rate: 0.0
# vision backbone
resolution: ${model.image.resolution}
# audio backbone
max_audio_len: ${running.audio.max_len}
num_mel_bins: ${running.audio.num_mel_bins}

# unused but to be compatible w/ audioset_cap.py
frame_key: "frame"
frame_emb: null
clf: False
weighted_sampling: False
